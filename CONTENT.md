All implementations from scratch

1. Basic Introduction (In slides, what is supervised, unsupervised learning, steps on working with data, training set test set, epochs)
2. Deflating the hype - Listing down th concepts much needed for ML..
3. Basics of LA (Scalar Product, Vector Product, Matrices, Transformation of Matrices, Gradient, Hessian, Eigenvalues - for optimisation)
Resource - http://cs229.stanford.edu/section/cs229-linalg.pdf
4. Basics of PS (Probability, conditional probability, Random Variables, Bayes theorem (EXPLAIN IN DETAIL THIS ONE))
Resource to read - http://cs229.stanford.edu/section/cs229-prob.pdf
5. Basics of Calculus - (Partial Derivatives, Jacobian, Gradient)
6. Intuition (Just touch upon) - (Cost Function, Gradient Descent)
7. Start with Linear Regression - Intuition, Math, explanation using Demo/Diagram, Code
8. Naive Bayes Classifier - Intuition, Math, explanation using Demo/Diagram, Code
9. K-means Clustering - Intuition, Math, explanation using Demo/Diagram, Code
10. Resources (to the audience) - First Coursera, then CS229...blah blah

